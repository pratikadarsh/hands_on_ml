{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accepting-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page 667, function for generating univariate time series.\n",
    "import numpy as np\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time-offsets1) * (freq1 * 10 + 10)) # wave 1\n",
    "    series += 0.2 * np.sin((time-offsets2) * (freq2 * 20 + 20)) # +wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # +noise\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page 668, create test, train and validation set.\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "architectural-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021970443\n"
     ]
    }
   ],
   "source": [
    "#page 668, calculating baseline metrics.\n",
    "import keras\n",
    "\n",
    "y_pred = X_valid[:, -1]\n",
    "naive_loss = np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
    "print(naive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binary-singapore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - 0s 901us/step - loss: 0.1755\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 0s 954us/step - loss: 0.0885\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 0s 826us/step - loss: 0.0532\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 0s 920us/step - loss: 0.0369\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 0s 907us/step - loss: 0.0283\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 0s 817us/step - loss: 0.0230\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 0s 887us/step - loss: 0.0193\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 0s 894us/step - loss: 0.0166\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 0s 837us/step - loss: 0.0147\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 0s 870us/step - loss: 0.0134\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 0s 848us/step - loss: 0.0123\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 0s 837us/step - loss: 0.0115\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 0s 802us/step - loss: 0.0109\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 0s 770us/step - loss: 0.0103\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 0s 875us/step - loss: 0.0098\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 0s 906us/step - loss: 0.0094\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 0s 817us/step - loss: 0.0090\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.008 - 0s 862us/step - loss: 0.0087\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 0s 863us/step - loss: 0.0083\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 0s 780us/step - loss: 0.0080\n",
      "0.008039478\n"
     ]
    }
   ],
   "source": [
    "#page 669, calculating baseline using fully connected layer.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50,1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "y_pred = model.predict(X_valid)\n",
    "fc_loss = np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
    "print(fc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atlantic-boundary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 1.0249\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.9838\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.9145\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.8141\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.7639\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.7365\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.6942\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.6158\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.5280\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.5064\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4944\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4754\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4549\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4355\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.4166\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.3951\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.3654\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.3371\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.3114\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 1s 7ms/step - loss: 0.2907\n",
      "0.27918857\n"
     ]
    }
   ],
   "source": [
    "#page 669, a simple one neuron RNN.\n",
    "model = keras.models.Sequential([keras.layers.SimpleRNN(1, input_shape=[None, 1])])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "y_pred = model.predict(X_valid)\n",
    "one_neuron_loss = np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
    "print(one_neuron_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "radical-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0869\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0085\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0060\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0050\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0046\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0043\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0041\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0039\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0039\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0037\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0036\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0036\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0035\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0034\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0034\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0034\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0034\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0033\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 2s 24ms/step - loss: 0.0033\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0032\n",
      "0.003561747\n"
     ]
    }
   ],
   "source": [
    "#page 672, Deep RNN.\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "y_pred = model.predict(X_valid)\n",
    "deep_loss = np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
    "print(deep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "viral-converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.1607\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0196\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0133\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0097\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0073\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0059\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0048\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0043\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0038\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0036\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0034\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0033\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0031\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0031\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0030\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0030\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0030\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.0029\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0029\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.0029\n",
      "0.0028394365\n"
     ]
    }
   ],
   "source": [
    "#page 673, Deep RNN with the final layer as Dense.\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "y_pred = model.predict(X_valid)\n",
    "deep_dense_loss = np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
    "print(deep_dense_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conservative-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.61607623]\n",
      "  [-0.5220552 ]\n",
      "  [-0.35766116]\n",
      "  [-0.16591613]\n",
      "  [ 0.01490751]\n",
      "  [ 0.14437921]\n",
      "  [ 0.25328743]\n",
      "  [ 0.30594236]\n",
      "  [ 0.366873  ]\n",
      "  [ 0.41049102]]]\n"
     ]
    }
   ],
   "source": [
    "#page 674, Forecasting several timesteps ahead. This is done by using the output and adding it into the input data.\n",
    "# then doing prediction and again adding the output to the input and so on.\n",
    "\n",
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "Y_pred = X[:, n_steps:]\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "collectible-december",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1715\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1463\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1454\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.1451\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1449\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1449\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.1447\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1446\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1446\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1445\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.1445\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1445\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1445\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1445\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1445\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.1445\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.1444\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1445\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1444\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.1444\n",
      "0.14614816\n"
     ]
    }
   ],
   "source": [
    "#page 675, Forecasting several timesteps ahead by adding a multi-neuron layer at the end.\n",
    "\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "y_pred = model.predict(X_valid)\n",
    "deep_dense_loss = np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n",
    "print(deep_dense_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opposite-leeds",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-82eae48146b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-helen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
